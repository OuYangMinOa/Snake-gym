## Conclusion
* In this case, Don't do observation normalize
* If model is small, use tanh as your activation function
* If model is large, use Mish/ReLU/Softsign as your activation function
* Small model with Mish/ReLU/Softsign is bad
* So reward normalization
* Don't do reward scaling
